> This project is part of the applied AI work organized in:
> https://github.com/WaSilveira/ai-life-sciences

# Calculo-de-Metricas-de-Avaliacao-de-Aprendizado
# Model Evaluation Metrics in a Health Data Context

## Context
This repository originated from a structured learning exercise and was extended to explore how **machine learning evaluation metrics behave in a real-world health-related scenario**, using COVID-19 data as context.

In applied AI, especially in healthcare, **model performance must be interpreted carefully**, as metrics directly influence decisions, trust, and risk.

## Objective
To analyze and compute key machine learning evaluation metrics — such as accuracy, precision, recall, F1-score, and confusion matrix — and discuss their meaning and limitations when applied to health data.

## Approach
- Use Python to compute and compare standard evaluation metrics  
- Apply the metrics to a dataset inspired by COVID-19 scenarios  
- Emphasize interpretation rather than model optimization  
- Highlight trade-offs between metrics in sensitive contexts

## Key Learnings
- Evaluation metrics can be misleading if interpreted in isolation  
- In health-related problems, recall and precision often matter more than raw accuracy  
- Metric choice directly impacts decision-making and risk assessment  
- Responsible AI requires understanding *why* a model performs as it does

## Notes
This repository is part of an ongoing process of applied learning and experimentation in machine learning, with particular attention to **healthcare, data responsibility, and decision support**.
